#+TITLE: Introduction to Machine Learning, Bachelor course
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \input{preamble}
#+LaTeX_CLASS_OPTIONS: [smaller]
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3
* General
** Introduction
*** Summary
This course gives an introduction to the algorithms and theory of
machine learning. Application is in the form of a course project.
During the course, you will be able to:

- Formalise a scientific question and answer it using machine learning.
- Distinguish between different variable types and their relations.
- Perform experiment design, data collection and analysis.
- Understand core machine learning principles.
- Implement and understand some of the simplest algorithms.
- Apply off-the-shelf algorithms from existing Python libraries.

The course focuses on fundamental modelling problems and general machine learning methodology. Theory is only briefly mentioned.


** Schedule
|--------+-------+----------------------------------------+------------------------------------------------------------------+---------------------+-------|
| Module |  Date | Topic                                  | Details                                                          | Python              | Type  |
|--------+-------+----------------------------------------+------------------------------------------------------------------+---------------------+-------|
|      1 | 09.17 | Introduction                           | Mean estimation, kNN, Train/Test                                 | nympy, pandas       | Mixed |
|      2 | 09.24 | Generalisation, kNN, Decision problems | kNN, Generalisation, Decision Problems                           | pandas, scikitlearn | Mixed |
|      3 | 10.01 | The Perceptron, Model Comparison       | The Perceptron, Cross-Validation, Bootstrapping, Model Selection | scikit learn        | Mixed |
|      4 | 10.08 | Regression                             | Linear regression, SGD                                           | sklearn             | Mixed |
|      5 | 10.15 | Regression lab, Simulation, Project    | Lab, Feature Selection for Regression                            | sklearn             | Lab   |
|      6 | 10.22 | Multi-layer Perceptrons                | Cost functions, Backpropagation, Layers                          | sklearn/pytorch     | Mix   |
|      7 | 10.29 | Probabilistic machine learning         | ML, MAP, Bayesian Infernece, Beta-Bernoulli: hypotheses          |                     | Lab   |
|      8 | 11.05 | Generative models                      | Naive Bayes, Graphical models, independence                      |                     | Mix   |
|      9 | 11.12 | Sequence prediction                    | Markov models, text prediction, LLMs                             |                     | Mixed |
|     10 | 11.19 | Ensemble methods                       | Bagging, boosting                                                |                     | Mixed |
|     11 | 11.26 | Image recognition                      |                                                                  |                     | Lab   |
|     12 | 12.03 | Fairness and Privacy                   |                                                                  |                     | Mixed |
|     13 | 12.10 | Project Presentations                  |                                                                  |                     | Lab   |
|--------+-------+----------------------------------------+------------------------------------------------------------------+---------------------+-------|
|     14 | 12.17 | Project work                           |                                                                  |                     | Lab   |
|--------+-------+----------------------------------------+------------------------------------------------------------------+---------------------+-------|

** Material
*** Textbooks
**** Primary
- Introduction to Statistical Learning with Python
https://hastie.su.domains/ISLP/ISLP_website.pdf.download.html
** Notation differences
*** Random variables
The ISLP book typically denotes random variables with a capital letter, i.e. $X, Y$ and their probabilities with $P(X | Y)$. For specific values, it typically uses the small letters, e.g.
$P(X = x | Y = y)$.

We will not use this convention, and stick to small letters, e.g. writing 
\[
P(x = i | y = j)
\] or
\[
P(x_t = x | y_t = y).
\]

Sometimes we use the shorthand $\sum_x P(x, y)$ to mean $\sum_{i \in X} P(x = i | y)$.

*** Sets
We will use  capital letters e.g. $A, B, C$ for sets. For special sets, we will use calligraphic capital letters, e.g. $\CA, \CX, \CY$.

*** Models versus decision rules
The ISLP book makes no real distinction between decision rules and models. It sometimes uses $P$, $\hat{P}$ or $\hat{Pr}$ for an estimated model. We use:
- $\pi$ for a decision rule.
- $P$ for a model
- $\param$ for the parameters of a model, with $P_\param$ the parametrised model.
- $\hat{\param}$ for estimated parameters.

* Course evaluation
** Course evaluation
*** Course evaluation
- Remember to do the course evaluation on is-academia.
- This helps us improve the course.
- Try to leave text comments. These are more informative than simple
  scores. We would like to know what you found easy, what you found
  hard, what was a big problem for you, what you enjoyed, etc.

* Activities
** Assignments
*** Assignment 0: Probability exercise, classification/regression
 - Reminder of probability and expectation
 - Examples of classification and regression

*** Assignment 1: k-Nearest Neighbour, performance
 Here we look at different methods to measure model performance.
 Using scikitlearn, see how data rescaling affects performance.
 Then measure performance under an alternative measure.

*** Assignment 2: Perceptron, model comparison
 In this assignment we compare classification models. 
 We apply the basic ideas of train, test, validation, cross-validation and bootstrapping. 
 They should develop this using scikitlearn.
*** Assignment 3: Linear regression and simulation

**** Regression
Complete the in-class exercise:

(a) Use the sm.OLS() function to perform a multiple linear regression
with weight as the response and all other variables (except name) as
the predictors. Use the summarize() function to print the results.

Comment on the output. For instance:

i. Is there a relationship between the predictors and the re-
sponse? 

ii. What does the coefficient for the gender variable suggest?

iii. Produce some of diagnostic plots of the linear regression fit as
described in the lab. Comment on any problems you see with the
fit. Do the residual plots suggest any unusually large outliers?
Does the leverage plot identify any observations with unusually
high leverage?

iv. Try a few different transformations of the variables, such as \(\log(x)\) or \(\sqrt{x}\)

**** Simulation


In this exercise you will create some \emph{simulated} data and will fit 
\emph{linear regression models} to it. 

(a) Generate 100 values \(x_t\) from the normal distribution, i.e. \(x_t \sim N(0,1)\).

(b) Generate a vector \(y\) using the formula
\[
y_t = 1 - 2 x_t + \epsilon_t, 
\]
with \(\epsilon_t \sim N(0,0.5)\), i.e. with zero men and variance 0.5.

(c) Create a scatterplot between x, y and comment on what you observe.


(e) Fit a least squares linear model to predict y using x . Comment
on the model obtained. How do the estimated \(\beta_0, \beta_1\) compare to the true values?

(f) Plot the true regression line  with the given parameters.

(g) Repeat steps \(a-f\) with the following modification:

i. Generate 10-dimensional \(x_t\) from the normal distribution, i.e. \(x_{t,i} \sim N(0,1)\).

ii. Generate the vector \(y\) only using the first feature, \(x_{t,1}\), i.e.
\[
y_t = 1 - 2 x_{t,1} + \epsilon_t.
\]
This means that the coefficients \(\beta_2, \ldots, \beta_10 = 0\).

In what way are your results different?

(h) Repeat (g), but generate 10,000 points \((x_t, y_t)\) instead of only 100.

*** Assignment 4: Basic neural networks
- sigmoid functions
- Single layer networks
- Multi-layer networks
- Numerical example
- Computational graph
- pyTorch neural networks
- Model

*** Assignment 5: Probabilistic Models



Complete the notebook in https://github.com/olethrosdc/machine-learning-neuch/blob/main/BSc/src/bayesian/priors-posteriors.ipynb to calculate the beta-Bernoulli posterior

*** Assignment 6: Graphical models, generative models and simulation


    Describe the main variables of your project.
    Define their possible dependencies with a graphical model.
    Create a generative model that satisfies the given dependencies, even if the exact probabilistic relationship between the variables is not yet known.
    Use the generative model as a simulation to generate data similar to the one you have in your own project, simplifying if possible.

This assignment is a stepping stone for you to then perform an analysis on data you generate from the simulation.

Complete both tasks notebook in https://github.com/olethrosdc/machine-learning-neuch/blob/main/BSc/src/Featureselection/feature_selection.ipynb related to your group project.

You should do it in group. One submission per group and add all name members in the notebook and\or pdf.

*** Assignment 7: Tree-based methods

Complete all the  notebook tasks in https://github.com/olethrosdc/machine-learning-neuch/blob/main/BSc/src/Tree-basedmethods/tree_based.ipynb. 

- Examine how tree depth / bagging / random forests affect predictions





*** Assignment 8: Neural networks
    Image classification example.

Complete Assignment 1 of this notebook: [[https://github.com/olethrosdc/machine-learning-neuch/blob/main/BSc/src/Image%20Processing/image_processing.ipynb]]  and assignment 2 of the second notebook : 
[[https://github.com/olethrosdc/machine-learning-neuch/blob/main/BSc/src/Image%20Processing/cnn.ipynb]]


** Projects

*** Project structure
 The students will develop a data analysis project that includes the following:

 1. Selection of a scientific question that can be answered through data collection and analysis.
 2. Choice of variables that can answer this question.
 3. Simulation of the data generating process to select a data analysis methodology.
 4. Collection of data guided by the simulation.
 5. Data analysis guided by the simulation

Throughout the course, we have assignments that are related to your project, and that can help you prepare material for the project itself, and obtain early feedback. You can then build on the material you developed in the assignments for your project. Those assignments that are directly linked to the project are done in *groups*.

*** Project presentation/report contents
Your project presentation, as well as the final report, must contain the following details:

1. Define a scientific question (e.g. are women better in math?). Does it potentially involve any ethical issues? 
2. Simulator. What are the dependencies between the variables? Specify a graphical model for those dependencies? How can we modify it so we get different answers? (e.g in one simulator math ability is independent of gender; in another, it depends on educational stimulus, which depends on gender).
3. Data sources, if any. Data collection methodology, if any. (Otherwise rely on the simulation). Does data collection relate to private data, or any other possible ethical issues?
4. Pipeline. How do you process data reliably? Explain how all steps that you perform, including scaling the data, filtering out possible outliers, dealing with missing values. Explain which parts are automated, and which parts involve personal choices.
5. Methodology. What methods are you using to answer the question? How do you justify them? Explain how and why you are using a specific machine learning algorithm. What are the theoretical and practical reasons for this choice? 
6. Summary results: plots, graphs, tables, etc. These should be design so as to show the empirical relations between the variables of interest, and can include histograms, density plots,  regression plots, classification boundaries, confidence intervals, regression coefficients, for example.
7. Conclusion based on your results. Can you answer the question? How much data do you need to answer the question clearly? In which cases does your methodology provide reliable results?  If you are using a simulator, you can test the reliability of your methodology by seeing how close the results are to the ground truth. Are there any ethical issues involved, e.g. related to fairness, privacy, or safety? Justify your answers. 
   
*** Report Grading
 The *criteria* for obtaining full marks in the project are the following. 
 
 1. Documenting of the work in a way that enables reproduction.
 2. Technical correctness of their analysis.
 3. Demonstrating that they have understood the assumptions underlying their analysis.
 4. Addressing issues of reproducibility in research.
 5. Addressing scientific and ethical questions where applicable, and if not, clearly explain why they are not.
 6. Consulting additional resources beyond the source material with proper citations.

 The follow marking guidelines are what one would expect from students attaining each grade. 


*** A (6)


 1. Submission of a detailed report from which one can definitely reconstruct their work without referring to their code. There should be no ambiguities in the described methodology. Well-documented code where design decisions are explained. 
 2. Extensive analysis and discussion. Technical correctness of their analysis. Nearly error-free implementation.
 3. The report should detail what models are used and what the assumptions are behind them. The conclusions of the should include appropriate caveats.  When the problem includes simple decision making, the optimality metric should be well-defined and justified. Simiarly, when well-defined optimality criteria should given for the experiment design, when necessary. The design should be (to some degree of approximation, depending on problem complexity) optimal according to this criteria.
 4. Appropriate methods to measure reproducibility. Use of cross-validation or hold-out sets to measure performance. Use of an unbiased methodology for algorithm, model or parameter selection. Appropriate reporting of a confidence level (e.g. using bootstrapping) in their analytical results. Relevant assumptions are mentioned when required.
 5. A clear definition of a scientific question. When dealing with data relating to humans, ethical concerns, such as privacy and/or fairness should be addressed.
 6. The report contains some independent thinking, or includes additional resources beyond the source material with proper citations. The students go beyond their way to research material and implement methods not discussed in the course.

*** B (5.5)

 1. Submission of a report from which one can plausibly reconstruct their work without referring to their code. There should be no major ambiguities in the described methodology. 
 2. Technical correctness of their analysis, with a good discussion. Possibly minor errors in the implementation.
 3. The report should detail what models are used, as well as the optimality criteria, including for the experiment design. The conclusions of the report must contain appropriate caveats. 
 4. Use of cross-validation or hold-out sets to measure performance. Use of an unbiased methodology for algorithm, model or parameter selection. 
 5. When dealing with data relating to humans, ethical concerns such as privacy and/or fairness should be addressed. While an analysis of this issue may not be performed, there is a substantial discussion of the issue that clearly shows understanding by the student.
 6. The report contains some independent thinking, or the students mention other methods beyond the source material, with proper citations, but do not further investigate them.
   
*** C (5)

 1. Submission of a report from which one can partially reconstruct most of their work without referring to their code. There might be some ambiguities in parts of the described methodology. 
 2. Technical correctness of their analysis, with an adequate discussion. Some errors in a part of the implementation.
 3. The report should detail what models are used, as well as the optimality criteria and the choice of experiment design. Analysis caveats are not included.
 4. Either use of cross-validation or hold-out sets to measure performance, or use of an unbiased methodology for algorithm, model or parameter selection - but in a possibly inconsistent manner.
 5. When dealing with data relating to humans, ethical issues are addressed superficially.
 6. There is little mention of methods beyond the source material or independent thinking.

*** D (4.5)

 1. Submission of a report from which one can partially reconstruct most of their work without referring to their code. There might be serious ambiguities in parts of the described methodology. 
 2. Technical correctness of their analysis with limited discussion. Possibly major errors in a part of the implementation.
 3. The report should detail what models are used, as well as the optimality criteria. Analysis caveats are not included.
 4. Either use of cross-validation or hold-out sets to measure performance, or use of an unbiased methodology for algorithm, model or parameter selection - but in a possibly inconsistent manner.
 5. When dealing with data relating to humans, ethical issues are addressed superficially or not at all.
 6. There is little mention of methods beyond the source material or independent thinking.

*** E (4)
 1. Submission of a report from which one can obtain a high-level idea of their work without referring to their code. There might be serious ambiguities in all of the described methodology. 
 2. Technical correctness of their analysis with very little discussion. Possibly major errors in only a part of the implementation.
 3. The report might mention what models are used or the optimality criteria, but not in sufficient detail and caveats are not mentioned.
 4. Use of cross-validation or hold-out sets to simultaneously measure performance and optimise hyperparameters, but possibly in a way that introduces some bias.
 5. When dealing with data relating to humans, ethical issues are not discussed.
 6. There is no mention of methods beyond the source material or independent thinking.

*** F ($\leq 3.5$)

 1. The report does not adequately explain their work.
 2. There is very little discussion and major parts of the analysis are technically incorrect, or there are errors in the implementation.
 3. The models used might be mentioned, but not any other details.
 4. There is no effort to ensure reproducibility or robustness.
 5. When applicable: Ethical issues are not mentioned.
 6. There is no mention of methods beyond the source material or independent thinking.
    

