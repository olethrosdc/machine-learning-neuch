#+TITLE: Machine Learning and Data Mining, Master course
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \usepackage{tikz}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{amssymb}
#+LaTeX_HEADER: \usepackage{isomath}
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Var {\mathop{\mbox{\ensuremath{\mathbb{V}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Bias {\mathop{\mbox{\ensuremath{\mathbb{B}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \DeclareMathOperator*{\sgn}{sgn}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+LaTeX_HEADER: \newcommand \vparam {\vectorsym{\theta}}
#+LaTeX_HEADER: \newcommand \mparam {\matrixsym{\Theta}}
#+LaTeX_HEADER: \newcommand \bW {\matrixsym{W}}
#+LaTeX_HEADER: \newcommand \bw {\vectorsym{w}}
#+LaTeX_HEADER: \newcommand \wi {\vectorsym{w}_i}
#+LaTeX_HEADER: \newcommand \wij {w_{i,j}}
#+LaTeX_HEADER: \newcommand \bA {\matrixsym{A}}
#+LaTeX_HEADER: \newcommand \ai {\vectorsym{a}_i}
#+LaTeX_HEADER: \newcommand \aij {a_{i,j}}
#+LaTeX_HEADER: \newcommand \bx {\vectorsym{x}}
#+LaTeX_HEADER: \newcommand \bel {\beta}
#+LaTeX_HEADER: \newcommand \Ber {\textrm{Bernoulli}}
#+LaTeX_HEADER: \newcommand \Beta {\textrm{Beta}}
#+LaTeX_HEADER: \newcommand \Normal {\textrm{Normal}}
#+LaTeX_CLASS_OPTIONS: [smaller]
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3
* General
** Introduction
*** Summary
This course gives an introduction to the algorithms and theory of
machine learning. Application is in the form of a course project.
During the course, you will be able to:

- Formulate machine learning problems in terms of opimisation or probabilistic inference.
- Understand the fundamental machine learning algorithms.
- Be able to implement some of the simplest algorithms.
- Apply off-the-shelf algorithms from scikit-learn to problems.
- Develop custom models using the pyTorch library.

The course focuses on algorithms and models, firstly on
optimisation-based learning, and the secondly on probabilistic
learning.


*** Schedule

There are three types of sessions:
- Lecture sessions
- Mixed
- Lab

|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|
| Module |  Date | Topic                       | Details                                             | Python              | Type    |
|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|
|      1 | 09.19 | Introduction                | Mean estimation, Classification, kNN                | nympy, pandas       | Lecture |
|      2 | 09.26 | Learning and Generalisation | Train/Test, XV, Bootstrapping, Simulation           | pandas, scikitlearn | Mixed   |
|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|
|      3 | 10.03 | Classification, Perceptron  | Margin, Regret, Gradient Descent                    | scikit learn        | Mixed   |
|      6 | 10.10 | Neural Networks             | Logistic Regression, Backpop, Stochastic GD         | pyTorch intro       | Mixed   |
|      5 | 10.17 | Neural Network Lab          | Project discussion, Linear Regression Lab           | pyTorch             | Lab     |
|      4 | 10.24 | Regression, Linear          | Linear regression, Least Squares, Probabilistic     | pyTorch             | Mixed   |
|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|
|      7 | 10.31 | Probabilistic models        | ML, MAP, Bayes, Beta-Bernoulli, Hypothesis testing  |                     | Lecture |
|      8 | 11.07 | Generative modelling        | Bayesian Networks, Markov Models, Tree Models, CRFs |                     | Mixed   |
|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|
|      9 | 11.14 | Ensemble Models             |                                                     |                     | Mixed   |
|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|
|     10 | 11.21 | Fairness & Privacy          | Fairness definitions                                |                     | Lecture |
|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|
|     11 | 11.28 | Reinforcement Learning      |                                                     |                     | Mixed   |
|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|
|     12 | 12.05 | Project work                |                                                     |                     | Free    |
|     13 | 12.12 | Project Presentations       |                                                     |                     | EXAM    |
|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|
|     14 | 12.19 | Special Exam                |                                                     |                     | EXAM    |
|--------+-------+-----------------------------+-----------------------------------------------------+---------------------+---------|

**** 1. Introduction, KNN

PML1 Chapter 2.1-2.24, 
PML2 Chapter 2.1
ISLP Chapter 1, 4.7.6
ESL Chapter 13

**** 2. Generalisation

PML1 Chapter 5.1, 5.3
ISLP Chapter 2, 4.7.6


** Material
*** Textbooks
**** Primary
- Introduction to Statistical Learning with Python
https://hastie.su.domains/ISLP/ISLP_website.pdf
- Elements of Statistical Learning
https://hastie.su.domains/Papers/ESLII.pdf
**** Secondary
- Probabilistic Machine Learning: An Introduction
https://probml.github.io/pml-book/book1.html
https://github.com/probml/pml-book/releases/latest/download/book1.pdf
- Probabilistic Machine Learning: Advanced Topics
https://probml.github.io/pml-book/book2.html
https://github.com/probml/pml2-book/releases/latest/download/book2.pdf



**** Links to reference material

ISLP: Introduction to Statistical Learning with Python
ESL2: Elements of Statistical Learning (2nd Ed)
PML1: Probabilistic Machine Learning: An Introduction
PML2: Probabilistic Machine Learning: Advanced Topics

|-----------------------------+------+------+------+------|
| Topic                       | ISLP | ESL2 | PML1 | PML2 |
|-----------------------------+------+------+------+------|
| Linear Regression           |    3 |    3 |      |      |
| Nearest Neighbours          |  3,4 |   13 |      |      |
| Linear Classification       |    4 |    4 |      |      |
| Model Selection             |    5 |    7 |      |      |
| Linear Model Regularization |    6 |    3 |      |      |
| Basis Expansions            |    7 |    5 |      |      |
| Kernel Smoothing            |    7 |    6 |      |      |
| Additive Models             |    7 |    9 |      |      |
| Model Inference/Averaging   |    8 |    8 |      |      |
| Random Forests              |    8 |   15 |      |      |
| Ensemble Learning           |    8 |   16 |      |      |
| Trees                       |    8 |    9 |      |      |
| Boosting                    |    8 |   10 |      |      |
| Expectation Maximisation    |    * |    8 |      |  6.5 |
| SVMs                        |    9 |   12 |      |      |
| Neural Netowrks             |   10 |   11 |      |      |
| Censored Data               |   11 |   18 |      |      |
| Unsupervised Learning       |   12 |   14 |      |      |
| Undirected Graphical Models |    * |   17 |      |      |
| Hypothesis tesing           |   13 |   18 |      |      |
| High-Dimensional Statisitcs |    6 |   18 |      |      |
|-----------------------------+------+------+------+------|

* Projects

** Project structure
 The students will develop a data analysis project that includes the following:

 1. Selection of a scientific question that can be answered through data collection and analysis.
 2. Choice of variables that can answer this question.
 3. Simulation of the data generating process to select a data analysis methodology.
 4. Collection of data guided by the simulation.
 5. Data analysis guided by the simulation

Throughout the course, we have assignments that are related to your project, and that can help you prepare material for the project itself, and obtain early feedback. You can then build on the material you developed in the assignments for your project. Those assignments that are directly linked to the project are done in *groups*.

** Project presentation/report contents
Your project presentation, as well as the final report, must contain the following details:

1. Define a scientific question (e.g. are women better in math?). Does it potentially involve any ethical issues? 
2. Simulator. What are the dependencies between the variables? Specify a graphical model for those dependencies? How can we modify it so we get different answers? (e.g in one simulator math ability is independent of gender; in another, it depends on educational stimulus, which depends on gender).
3. Data sources, if any. Data collection methodology, if any. (Otherwise rely on the simulation). Does data collection relate to private data, or any other possible ethical issues?
4. Pipeline. How do you process data reliably? Explain how all steps that you perform, including scaling the data, filtering out possible outliers, dealing with missing values. Explain which parts are automated, and which parts involve personal choices.
5. Methodology. What methods are you using to answer the question? How do you justify them? Explain how and why you are using a specific machine learning algorithm. What are the theoretical and practical reasons for this choice? 
6. Summary results: plots, graphs, tables, etc. These should be design so as to show the empirical relations between the variables of interest, and can include histograms, density plots,  regression plots, classification boundaries, confidence intervals, regression coefficients, for example.
7. Conclusion based on your results. Can you answer the question? How much data do you need to answer the question clearly? In which cases does your methodology provide reliable results?  If you are using a simulator, you can test the reliability of your methodology by seeing how close the results are to the ground truth. Are there any ethical issues involved, e.g. related to fairness, privacy, or safety? Justify your answers. 
   
** Report Grading
 The *criteria* for obtaining full marks in the project are the following. 
 
 1. Documenting of the work in a way that enables reproduction.
 2. Technical correctness of their analysis.
 3. Demonstrating that they have understood the assumptions underlying their analysis.
 4. Addressing issues of reproducibility in research.
 5. Addressing scientific and ethical questions where applicable, and if not, clearly explain why they are not.
 6. Consulting additional resources beyond the source material with proper citations.

 The follow marking guidelines are what one would expect from students attaining each grade. 


** A (6)


 1. Submission of a detailed report from which one can definitely reconstruct their work without referring to their code. There should be no ambiguities in the described methodology. Well-documented code where design decisions are explained. 
 2. Extensive analysis and discussion. Technical correctness of their analysis. Nearly error-free implementation.
 3. The report should detail what models are used and what the assumptions are behind them. The conclusions of the should include appropriate caveats.  When the problem includes simple decision making, the optimality metric should be well-defined and justified. Simiarly, when well-defined optimality criteria should given for the experiment design, when necessary. The design should be (to some degree of approximation, depending on problem complexity) optimal according to this criteria.
 4. Appropriate methods to measure reproducibility. Use of cross-validation or hold-out sets to measure performance. Use of an unbiased methodology for algorithm, model or parameter selection. Appropriate reporting of a confidence level (e.g. using bootstrapping) in their analytical results. Relevant assumptions are mentioned when required.
 5. A clear definition of a scientific question. When dealing with data relating to humans, ethical concerns, such as privacy and/or fairness should be addressed.
 6. The report contains some independent thinking, or includes additional resources beyond the source material with proper citations. The students go beyond their way to research material and implement methods not discussed in the course.

** B (5.5)

 1. Submission of a report from which one can plausibly reconstruct their work without referring to their code. There should be no major ambiguities in the described methodology. 
 2. Technical correctness of their analysis, with a good discussion. Possibly minor errors in the implementation.
 3. The report should detail what models are used, as well as the optimality criteria, including for the experiment design. The conclusions of the report must contain appropriate caveats. 
 4. Use of cross-validation or hold-out sets to measure performance. Use of an unbiased methodology for algorithm, model or parameter selection. 
 5. When dealing with data relating to humans, ethical concerns such as privacy and/or fairness should be addressed. While an analysis of this issue may not be performed, there is a substantial discussion of the issue that clearly shows understanding by the student.
 6. The report contains some independent thinking, or the students mention other methods beyond the source material, with proper citations, but do not further investigate them.
   

*** C (5)

1. Submission of a report from which one can partially reconstruct most of their work without referring to their code. There might be some ambiguities in parts of the described methodology. 
2. Technical correctness of their analysis, with an adequate discussion. Some errors in a part of the implementation.
3. The report should detail what models are used, as well as the optimality criteria and the choice of experiment design. Analysis caveats are not included.
4. Either use of cross-validation or hold-out sets to measure performance, or use of an unbiased methodology for algorithm, model or parameter selection - but in a possibly inconsistent manner.
5. When dealing with data relating to humans, ethical issues are addressed superficially.
6. There is little mention of methods beyond the source material or independent thinking.

*** D (4.5)

1. Submission of a report from which one can partially reconstruct most of their work without referring to their code. There might be serious ambiguities in parts of the described methodology. 
2. Technical correctness of their analysis with limited discussion. Possibly major errors in a part of the implementation.
3. The report should detail what models are used, as well as the optimality criteria. Analysis caveats are not included.
4. Either use of cross-validation or hold-out sets to measure performance, or use of an unbiased methodology for algorithm, model or parameter selection - but in a possibly inconsistent manner.
5. When dealing with data relating to humans, ethical issues are addressed superficially or not at all.
6. There is little mention of methods beyond the source material or independent thinking.

*** E (4)
1. Submission of a report from which one can obtain a high-level idea of their work without referring to their code. There might be serious ambiguities in all of the described methodology. 
2. Technical correctness of their analysis with very little discussion. Possibly major errors in only a part of the implementation.
3. The report might mention what models are used or the optimality criteria, but not in sufficient detail and caveats are not mentioned.
4. Use of cross-validation or hold-out sets to simultaneously measure performance and optimise hyperparameters, but possibly in a way that introduces some bias.
5. When dealing with data relating to humans, ethical issues are not discussed.
6. There is no mention of methods beyond the source material or independent thinking.

*** F (<3)

1. The report does not adequately explain their work.
2. There is very little discussion and major parts of the analysis are technically incorrect, or there are errors in the implementation.
3. The models used might be mentioned, but not any other details.
4. There is no effort to ensure reproducibility or robustness.
5. When applicable: Ethical issues are not mentioned.
6. There is no mention of methods beyond the source material or independent thinking.
* Exam subjects

The exam format does not allow any reference material. If there is a
need to know particular mathematical formula, it will be given in the
question itself. You are expected to be able to remember basic facts,
however.

Here are some example questions for the exam. Answers can range from simple one-liners to relatively complex designs. Half of the points will come from 10 1-point questions and the remaining from 2 or 3 2-5-point questions.

** Book Subjects

All non-programming exercises in the following chapters of the book "Statistical Learning with Python"  may appear in some form in the exam

- Ch. 2 Statistical Learning
- Ch. 3 Linear Regression
- Ch. 4 Classification
- Ch. 5 Resampling
- Ch. 10 Neural networks

In addition, exam questions similar to the ones below may also appear.


** Reproducibility

You are given a set of clinical data $x_1, \ldots, x_T$ with associated labels $y_1, \ldots, y_T$, where $y_t \in \{0,1\}$ indicates whether a patient has a disease. Each point $x_t$ is decomposable into $n$ features $x_{t,1}, \ldots, x_{t,n}$. Discuss how you can use a classification algorithm that estimates $\hat{P}(y | x)$ from the data in order to discover predictive features, and how you can validate your findings in a reproducibile manner.

*** Possible answer

(Many approaches are possible, the main thing I want to see is that you can validate your findings)

From a statistical point of view, we want to see the strength of the dependence between an individual feature (or set of features) and the data.
The strictest possible test is to see whether or not the labels are completely independent of a feature $i$ given the remaining features, i.e. we want to check that
\[
y_t \perp x_{t,i} \mid x_{t,-i} \qquad x_{t,-i} \defn x_{t, 1}, \ldots, x_{t, i-1}, x_{t, i+1},  x_{t, n}
\]
However this check is possibly too strict.

If this is the case, then $P(y_t \mid x_{t}) = P(y_t \mid x_{t,-i})$. One possible method is to fit the classification model of choice $\mu = \hat{P}(y_t \mid x_t)$ and a sequence of models $\mu_i = \hat{P}(y_t \mid x_{t,-i})$ on a subset $D_1$ of the dataset. Consequently, we can measure the likelihood of models on the remaining data $D_2$, so that we obtain
\[
\ell(\mu) = \prod_{t \in D_2} \hat{P}(y_t \mid x_t),
\qquad
\ell(\mu_i) = \prod_{t \in D_2} \hat{P}(y_t \mid x_{t,-i}).
\]
We may then consider all features $i$ with $\ell(\mu_i) < \ell(\mu)$ to be redundant. However, this may not be the case for two reasons:
1. If individually redundant features are correlated, then removing all of them may be difficult. For that reason, we may want to also test the performance of models which remove combinations of featutes.
2. Since probably no feature is completely useless, one reason for the apparent lack of predictive ability of some features maybe the amount of data we have. In the limit, if $y_t \perp x_{t,i} \mid x_{t,-i}$ then our estimators will satisfy $\hat{P}(y_t \mid x_{t}) = \hat{P}(y_t \mid x_{t,-i})$. However, it is hard to verify this condition when the amount of data is little. Conversely, with a lot of data, even weakly dependent features will not satisfy independence.


** Conditional probability and Bayesian inference

A prosecutor claims that the defendant is guilty because they have found DNA matching them on the scene of the crime. He claims that DNA testing has a false positive rate of one in a million ($10^{-6}$). While this is indeed evidence for the prosecution, it does not mean that the probability that the defendant is innocent is $10^{-6}$. What other information would you need to calculate the probability of the defendant being guilty given the evidence, and how would you incorporate it?

*** Possible answer
	CLOCK: [2019-11-20 ons 14:20]--[2019-11-20 ons 14:40] =>  0:20

Let us define the fact that the defendant committed a crime as $C$ and the converse as $\neg C$. Let us also denote the event that a test is positive as $T$. Let us also define the case where the DNA being tested is the one being compared to as $M$. Then the information we have is
\begin{align}
\Pr(T \mid \neg M) &= 10^{-6}
\\
T & \textrm{~is true}
\end{align}
In order to predict whether somebody has actually committed the crime given the information, we must calculate $\Pr(C \mid T)$.
This means we must calculate the following
\begin{align}
\Pr(C \mid T) &= \Pr(C \mid M) \Pr(M \mid T) + \Pr(C \mid \neg M) \Pr(\neg M \mid T)
\\
&= \Pr(C \mid M) [1 - \Pr(\neg M \mid T) + \Pr(C \mid \neg M) \Pr(\neg M \mid T)]
\\
&= \Pr(C \mid M) [1 - \Pr(T \mid \neg M) \Pr(\neg M) / \Pr(T) + \Pr(C \mid \neg M) \Pr(T \mid \neg M) \Pr(\neg M) / \Pr(T)],
&
\Pr(T) = \Pr(T \mid M) \Pr(M) + \Pr(T \mid \neg M) [1 - \Pr(M)]
\end{align}

As you can see, we are missing four important quantities. 
- $\Pr(M)$, the /a priori/ probability that this is the defendant's DNA 
- $\Pr(T \mid M)$ the probability of a test being positive if the DNA fragments come from the same person.
- $\Pr(C \mid M)$,  the probability that the defendant committed the crime if the DNA was really theirs.
- $\Pr(C \mid \neg M)$,  the probability that the defendant committed the crime if the DNA was not  theirs.

So the false positive rate is far from sufficient evidence for a conviction and must be combined with other evidence.


** Utility

  If $X$ is our set of rewards, our utility function is $U : X \to \Reals$ and we prefer reward $a$ to $b$ (and write $a >^* b$) iff $U(a) > U(b)$, then our preferences are transitive. Give an example of a preference relation $>^*$ among objects so that transitivity can be violated, e.g when $X = \Reals^2$. In that case, we cannot create a utility function that will satisfy the same relation. Back your example with a thought experiment.

*** Possible answer
	CLOCK: [2019-11-20 ons 14:40]--[2019-11-20 ons 14:58] =>  0:18

A simple example is when $U : \Reals^2 \to \Reals$, with rewards having two attributes. Then we might prefer $a$ to $b$ if $a_1 > b_1 + \epsilon$ , but if $|a_1 - b_1| \epsilon$ then we prefer $a$ to $b$ if $a_2 > b_2$. An example is if the first attribute is the IQ score of a job candidate and the second attribute their years of experience. We might prefer a brighter candidate as long as they are clearly much better (as IQ scores are fiddly), otherwise we will prefer the ones that have more experience. As an example, consider three candidates

| Id |  IQ | XP |
|----+-----+----|
| a  | 120 |  5 |
| b  | 130 |  4 |
| c  | 140 |  3 |
|----+-----+----|

In this example, we can set $\epsilon = 15$ so we prefer a candidate if he has at least an IQ score 15 points higher than another. 
Due to this, we have $a >^* c$. However, as $a$ and $b$ have similar IQs we prefer $a$ to $b$, i.e. $b >^* a$ and similarly $c >^* b$. If transitivity held, then we'd have $c >^* a$, which we don't.

Note that if we mapped these to a utility function, i.e. $U(a) = a_1 + a_2$, we will always get a transitive relation.


** Differential privacy

Consider a system where we obtain data $x_1, \ldots, x_n$ from
individuals, where $x_t \in X$ corresponds to data from a single
individual. Consider a mechanism that, from this data, publishes an
output $a_1, \ldots, a_n$ by partitioning $X$ in two sets, $A, B$ so
that $a_t = 1$ if $x_t \in A$ and $0$ otherwise.  Is the mechanism
$\pi(a | x)$ $\epsilon$-differentially private? If so, with what value
of $\epsilon$?

*** Possible answer
	CLOCK: [2019-11-20 ons 15:04]--[2019-11-20 ons 15:13] =>  0:09

In general, DP algorithms must be stochastic, so that this algorithm cannot satisfy DP at all.

In more detail, differential privacy requires that $\pi(a \mid x) \leq
\pi(a \mid x') e^\epsilon$ for some $\epsilon$ for any neighbouring
$x, x'$.  Consider a dataset where the $t$-th person has $x_t \in
A$. Then $a_t = 1$. Consider a neighbouring dataset where $x'_t \notin
A$. Then $a_t = 0$ w.p. 1, so $a_t = 1$ has probability $0$.

\[
\pi(a \mid x) = \prod_i \pi(a_i \mid x_i)  
= \pi(a_t \mid x_t)] \prod_{i \neq t} \pi(a_i \mid x_i) 
\]
\[
\pi(a \mid x') = \prod_i \pi(a_i \mid x_i) 
= [1 - \pi(a_t \mid x_t)] \prod_{i \neq t} \pi(a_i \mid x_i) 
\]
Dividing the two, we get
\[
\pi(a \mid x)   =  \pi(a \mid x') \pi(a_t \mid x_t)] / [1 - \pi(a_t \mid x_t)].
\]
However, the ratio on the right is not bounded (i.e. it can be $\infty$), hence there is no DP.


** Graphical models

A patient is coming to the doctor complaining of chest pains. The doctor recommends that the patient undergoes EEG examination in order to diagnose the patient's underlying condition and observes the result. Describe apropriate decision variables and random variables  corresponding to this problem and draw a graphical model detailing their relationship.

*** Possible answer
	CLOCK: [2019-11-20 ons 15:13]--[2019-11-20 ons 15:18] =>  0:05
Variables:
- C: Chest pain
- H: Underlying health condition
- P: Doctor policy
- X: examination decision
- Y: test result.

#+BEGIN_SRC
   {H}->(C)  
    |    | 
    v    v
   (Y)<-(X)<-[P]
#+END_SRC

[ ] indicates decision variables, ( ) observed random variables, { } latent variables



** Conditional independence

Consider four random variables $w, x, y, z$ with the following
properties: (a) $w$ is independent of $x$ given $y$ and $z$, (b) it is
not completely independent of $x$. Draw a graphical model that
satisfies them.

*** Possible answer
	CLOCK: [2019-11-20 ons 15:18]--[2019-11-20 ons 15:21] =>  0:03

(a) means that there is no path from $x$ to $w$ given $y, z$
(b) means that there is some path from $x$ to $w$. 

So a graphical model representing this is:

#+BEGIN_SRC
(z)--\ 
 ^    |
 |    v
(x)  (w)
 |    ^
 v    |
(y)--/
#+END_SRC

** Fairness
   CLOCK: [2019-11-20 ons 15:31]--[2019-11-20 ons 15:37] =>  0:06

Consider a decision problem where a decision maker (DM) takes actions affecting a set of individuals. Let the DM's action be $a \in A$. This action results in an outcome $y \in Y$, also depending on the underlying characteristics $x$ of the population and has conditional distribution $P(y \mid x, a)$.
Assume that the DM has a utility function $U : A \times Y \to \Reals$. 
1. Complete the following formula to show how the DM would maximise expected utility, assuming she observes $x$:
\[
\max_{a} \E [U \mid a, x]
\]
Note that $\E [U \mid a, x] = \sum_y U(a, y) P(y, \mid x, a)$.

2. Assume each individual $i$ also receives some utility from the DM's actions. This is specified through a collection of utility functions $v_i : A \times Y \to \Reals$. Two typical definitions of fairness from social choice theory concentrate on maximising a /social welfare/ function that depends on the utilities of the whole population. There are two typical such functions
 (a) The (expected) total utility of the population
 (b) The (expected) utility of the worst-off member of the population.
Formalise those definitions within our framework.

(a) Can be described as $V = \sum_i v_i$. Then the objective of the decision maker would be to find an $a$ maximising
\[
\E\left[\sum_i v_i \mid a, x\right]
=
\sum_y P(y \mid a, x) \sum_i v_i(a, y) 
\]
(b) can be described as  $V = \min_i v_i$. Similarly
\[
\E\left[\sum_i v_i \mid a, x\right]
=
\sum_y P(y \mid a, x) \min_i v_i(a, y) 
\]

3. Describe a method whereby the DM can trade-off maximising her own utility and social welfare. Under which conditions do the to objectives coincide?

A simple idea is to combine the social welfare linearly with the DM's utility. Then we can try to maximise
\[
\E[(1 - \alpha) U + \alpha V \mid x, a].
\]
The two objectives obviously coincide when $U = V$. However, any utility function $U$ which has the same maximum as $V$ is compatible with social welfare. 


** Causality (not this year)

Patients arrive at a hospital and receive a treatment that depends on their symptoms. The first table shows how many people receive each treatment. Assume that the number of people with each symptom is representative of the population.

|--------------+-----------+-----------|
| Applications | Symptom 1 | Symptom 2 |
|--------------+-----------+-----------|
| Treatment A  |        20 |        90 |
| Treatment B  |       180 |        10 |
|--------------+-----------+-----------|
Table 1: Number of treatment applications

The second table describes the number of people that were cured after the treatment was applied.

|-------------+-----------+-----------|
| Cured       | Symptom 1 | Symptom 2 |
|-------------+-----------+-----------|
| Treatment A |        15 |        60 |
| Treatment B |        90 |         4 |
|-------------+-----------+-----------|
Table 2: Effect of treatment

1 .Draw a graphical model with the following four variables:
- $\pi$: Treatment policy
- $x_t$: Symptoms
- $a_t$: Treatment
- $y_t$: Treatment effect



2. What would the expected curing rate of a policy that uniformly randomly assigned treatments have been? (It is OK to provide a simple point estimate)



3. Given the above data, what would be the treatment policy $\hat{\pi}^*$ that maximises the curing rate? and how much would the curing rate of $\hat{\pi}^*$ be?

4. Is there some reason why the original policy $\pi$ would be preferred to $\hat{\pi}^*$?

*** Possible answer

   CLOCK: [2019-11-20 ons 15:37]--[2019-11-20 ons 16:01] =>  0:24

1. Note that typically the symptoms and treatment effect depend on an underlying medical condition, but the question did not ask about this.
#+BEGIN_SRC
[$\pi$] ---> ($a_t$)
                ^   \
                |    \($y_t$)
                |    /
                |   /
             ($x_t$)
#+END_SRC




2. For S1, Treatment A works 15/20=3/4 and B: 90/180=1/2. Randomly assigning treatments: 3/8+1/4 = (3+2)/8 = 5/8
For S2, Treatment B works 60/90=2/3 and B: 4/10=2/5. Randomly assigning treatments: 1/3+1/5 = (3+5)/15 = 8/15
S1 has 200 patients and S2 has 100 patients, so 2/3 of people have S1. So the overall treatment rate would have been
5/8 * 2/3 + 8/15*1/3 = 10 / 24 + 8 / 45 ~ 5 / 12 + 2 / 11 ~ 7 / 12

3. It appears that Treatment A always works best, i.e. 3/4 of the time and 1/2 for each symptom.
So the overall curing rate based on the data would be 3/4 * 2/3 + 1/2*1/3 = 6/12 + 1/6 = 3/6+1/6 = 4/6=2/3.

4. Firstly, there could be hidden medical or financial costs. One treatment might be more expensive than the other, or may have more side-effects. In addition, one type of symptoms might be less acute or life-threatening than the other, thus requiring less aggressive treatment. Secondly, the new policy always uses the same treatment, and this means that we do not get information about the effectiveness of alternative treatments. This may be important in the initial stages of executing a treatment.


** Markov decision processes and experiment design (not this year)

   
Consider a Markov decision process with two actions $A = \{0, 1\}$ and three states $S = \{0, 1, 2\}$, with a horizon $T=2$, with starting state $s_1 = 10 and the following transition distribution:

$P(s_t = 0 \mid s_t = 0, a_t = 0) = 1$
$P(s_t = 1 \mid s_t = 0, a_t = 1) = 0.8$
$P(s_t = 2 \mid s_t = 0, a_t = 1) = 0.2$

We also receive a deterministic reward:
\[
r_t = \begin{cases}
0 & s_t = 0\\
1 & s_t = 1\\
-1 & s_t = 2
\end{cases}
\]

Since $T=2$, the MDP ends after we take the first action,observe Ss_2$ and obtain $r_2$. Our goal is to maximise
\[
\E \sum_{t=1}^2 r_t.
\]
What is the optimal policy for achieving that?


*** Possible answer
	CLOCK: [2019-11-20 ons 16:05]--[2019-11-20 ons 16:09] =>  0:04

We always start in state 1.
Taking action 0, we end up in state 1 again, with reward 0.
So $\E[\sum_{t=1}^2 r_t \mid a_1 = 0] = 0 + 0$.

Taking action 1, we end up in state 2 w.p 0.2 and state 1 w.p. 0.8.
So $\E[\sum_{t=1}^2 r_t \mid a_1 = 1] = 1 \times 0.8 - 1 \times 0.2 = 0.6$

So it is better to take action 1 in state 0. 
=======
    


